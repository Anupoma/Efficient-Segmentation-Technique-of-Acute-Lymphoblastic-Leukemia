{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3af137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image paths\n",
    "image_paths = [\n",
    "    \"D:/Thesis_4th/seg/Im018_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im001_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im002_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im003_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im004_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im005_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im006_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im007_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im008_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im009_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im010_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im011_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im012_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im013_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im014_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im015_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im016_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im055_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im054_1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Im019_1.jpg\",  \n",
    "    \"D:/Thesis_4th/seg/Im001_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im002_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im003_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im004_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im005_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im006_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im007_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im009_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im011_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im012_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im013_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im014_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im015_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im016_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im017_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im018_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im019_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im020_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im021_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im022_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im023_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im024_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im025_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im026_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im027_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im028_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im029_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im030_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im031_1.tif\",\n",
    "    \"D:/Thesis_4th/seg/Im032_1.tif\"\n",
    "]\n",
    "\n",
    "# List of ground truth image paths\n",
    "ground_truth_paths = [\n",
    "    \"D:/Thesis_4th/seg/Mask18.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask1.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask2.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask3.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask4.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask5.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask6.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask7.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask8.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask9.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask10.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask11.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask12.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask13.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask14.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask15.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask16.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask55.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask54.jpg\",\n",
    "    \"D:/Thesis_4th/seg/Mask19.jpg\",  \n",
    "    \"D:/Thesis_4th/seg/Mask01.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask02.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask03.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask04.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask05.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask06.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask07.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask09.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask11.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask12.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask13.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask14.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask15.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask16.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask17.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask18.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask19.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask20.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask21.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask22.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask23.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask24.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask25.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask26.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask27.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask28.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask29.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask30.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask31.tif\",\n",
    "    \"D:/Thesis_4th/seg/Mask32.tif\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cells(ground_truth_paths):\n",
    "    # Read the ground truth image (assumed to be binary: cells in white, background in black)\n",
    "    ground_truth_image = cv2.imread(ground_truth_paths, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply thresholding to convert the image to binary if it's not already\n",
    "    _, binary_image = cv2.threshold(ground_truth_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find connected components (cells) in the binary image\n",
    "    _, labels, stats, _ = cv2.connectedComponentsWithStats(binary_image)\n",
    "\n",
    "    # Count the number of cells (excluding the background label)\n",
    "    num_cells = len(stats) - 1\n",
    "\n",
    "    return num_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#watershed_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc777d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error_percentage_absolute_w = 0\n",
    "t_accu_w = 0\n",
    "total_tp_w = 0\n",
    "total_fp_w = 0\n",
    "total_fn_w = 0\n",
    "num_images = len(image_paths)\n",
    "\n",
    "# Loop through each image and ground truth pair in the lists\n",
    "for image_path, ground_truth_image_path in zip(image_paths, ground_truth_paths):\n",
    "    # Load the image and ground truth\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply color thresholding\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply median filtering for image enhancement\n",
    "    median_filtered_image = cv2.medianBlur(binary_image, ksize=5)\n",
    "\n",
    "    # Perform morphological operations to enhance cell boundaries\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened_image = cv2.morphologyEx(median_filtered_image, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    sure_bg = cv2.dilate(opened_image, kernel, iterations=3)\n",
    "\n",
    "    # Perform distance transform and thresholding to obtain sure foreground\n",
    "    dist_transform = cv2.distanceTransform(opened_image, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # Subtract sure foreground from sure background to get unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown_region = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Label markers for watershed segmentation\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add 1 to all markers to ensure background is 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Mark unknown region as 0\n",
    "    markers[unknown_region == 255] = 0\n",
    "\n",
    "    # Apply watershed segmentation\n",
    "    segmented_cells = cv2.watershed(image, markers)\n",
    "    image[segmented_cells == -1] = [255, 0, 0]\n",
    "\n",
    "    # Count cells\n",
    "    num_cells_detected = np.max(segmented_cells) - 1\n",
    "    num_cells = count_cells(ground_truth_image_path)\n",
    "    \n",
    "    if num_cells_detected > num_cells:\n",
    "        accuracy_w =  num_cells / num_cells_detected * 100\n",
    "    else:\n",
    "         accuracy_w =  num_cells_detected / num_cells * 100\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = min(num_cells_detected, num_cells)\n",
    "    fp = num_cells_detected - tp\n",
    "    fn = num_cells - tp\n",
    "\n",
    "    # Accumulate true positives, false positives, and false negatives for the average\n",
    "    total_tp_w += tp\n",
    "    total_fp_w += fp\n",
    "    total_fn_w += fn\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_score_percentage = f1_score * 100 \n",
    "\n",
    "    # Display the results\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(segmented_cells, cmap='jet')\n",
    "    axs[1].set_title('Segmented Cells')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Total number of cells (Ground Truth):\", num_cells)\n",
    "    print(\"Total number of cells (Detected):\", num_cells_detected)\n",
    "    \n",
    "    #total accuracy\n",
    "    t_accu_w += accuracy_w\n",
    "    #average accuracy\n",
    "    avg_accu_w = t_accu_w/num_images\n",
    "    print(\"accuracy:\", accuracy_w,\"%\")\n",
    "    print(\"F1 Score:\", f1_score_percentage, \"%\")\n",
    "    \n",
    "    # Calculate the error percentage\n",
    "    error_percentage = 100 - accuracy_w\n",
    "\n",
    "    # Calculate the error percentage in absolute value\n",
    "    error_percentage_absolute_w = abs(error_percentage)\n",
    "    \n",
    "    # Print the error percentage for the current image\n",
    "    print(\"Error Percentage for current image:\", error_percentage_absolute_w, \"%\")\n",
    "    \n",
    "    # Accumulate the error percentage for the average\n",
    "    total_error_percentage_absolute_w += error_percentage_absolute_w\n",
    "    \n",
    "    # Calculate the average error percentage\n",
    "    average_error_percentage_absolute_w = total_error_percentage_absolute_w / num_images\n",
    "    \n",
    "    # Calculate the average precision, recall, and F1 score\n",
    "    avg_precision = total_tp_w / (total_tp_w + total_fp_w)\n",
    "    avg_recall = total_tp_w / (total_tp_w + total_fn_w)\n",
    "    avg_f1_score_w = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    avg_precision_w = avg_precision * 100\n",
    "    avg_recall_w = avg_recall * 100\n",
    "    avg_f1_score_percentage_w = avg_f1_score_w * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Averagae accuracy:\", avg_accu_w, \"%\")\n",
    "print(\"Average Error:\", average_error_percentage_absolute_w, \"%\")\n",
    "print(\"Average F1 Score:\", avg_f1_score_percentage_w, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e135a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otsuâ€™s Binarization_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error_percentage_absolute_t = 0\n",
    "t_accu = 0\n",
    "total_tp_t = 0\n",
    "total_fp_t = 0\n",
    "total_fn_t = 0\n",
    "num_images = len(image_paths)\n",
    "\n",
    "# Loop through each image and ground truth pair in the lists\n",
    "for image_path, ground_truth_image_path in zip(image_paths, ground_truth_paths):\n",
    "    # Load the image and ground truth\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Median blurring to reduce noise (optional, adjust kernel size as needed)\n",
    "    blurred_image = cv2.medianBlur(gray_image, 5)\n",
    "\n",
    "    # Apply Otsu's Binarization\n",
    "    _, binary_img = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply morphological operations to remove small particles (adjust kernel size as needed)\n",
    "    kernel = np.ones((20, 20), np.uint8)  # Larger kernel to remove small particles\n",
    "    binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel)\n",
    "    binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours of the binary image\n",
    "    contours, _ = cv2.findContours(binary_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on their area to ignore smaller particles\n",
    "    min_area = 100  # Adjust this threshold as needed\n",
    "    white_blood_cells = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "    # Draw the filtered contours on the original image (for visualization)\n",
    "    segmented_image = image.copy()\n",
    "    cv2.drawContours(segmented_image, white_blood_cells, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    num_cells_detected = len(white_blood_cells)\n",
    "    \n",
    "    num_cells = count_cells(ground_truth_image_path)\n",
    "    \n",
    "    if num_cells_detected > num_cells:\n",
    "        accuracy =  num_cells / num_cells_detected * 100\n",
    "    else:\n",
    "         accuracy =  num_cells_detected / num_cells * 100\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = min(num_cells_detected, num_cells)\n",
    "    fp = num_cells_detected - tp\n",
    "    fn = num_cells - tp\n",
    "\n",
    "    # Accumulate true positives, false positives, and false negatives for the average\n",
    "    total_tp_t += tp\n",
    "    total_fp_t += fp\n",
    "    total_fn_t += fn\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_score_percentage = f1_score * 100\n",
    "\n",
    "\n",
    "    # Display the original image and segmented image\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title('Segmented Image (White Blood Cells)')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Total number of cells (Ground Truth):\", num_cells)\n",
    "    print(\"Total number of cells (Detected):\", num_cells_detected)\n",
    "\n",
    "    #total accuracy\n",
    "    t_accu += accuracy\n",
    "    #average accuracy\n",
    "    avg_accu = t_accu/num_images\n",
    "    print(\"accuracy:\", accuracy,\"%\")\n",
    "    print(\"F1 Score:\", f1_score_percentage, \"%\")\n",
    "    \n",
    "    # Calculate the error percentage\n",
    "    error_percentage = 100 - accuracy\n",
    "\n",
    "    # Calculate the error percentage in absolute value\n",
    "    error_percentage_absolute_t = abs(error_percentage)\n",
    "    \n",
    "    # Print the error percentage for the current image\n",
    "    print(\"Error Percentage for current image:\", error_percentage_absolute_t, \"%\")\n",
    "    \n",
    "    # Accumulate the error percentage for the average\n",
    "    total_error_percentage_absolute_t += error_percentage_absolute_t\n",
    "    \n",
    "    # Calculate the average error percentage\n",
    "    average_error_percentage_absolute_t = total_error_percentage_absolute_t / num_images\n",
    "    \n",
    "    # Calculate the average precision, recall, and F1 score\n",
    "    avg_precision = total_tp_t / (total_tp_t + total_fp_t)\n",
    "    avg_recall = total_tp_t / (total_tp_t + total_fn_t)\n",
    "    avg_f1_score_t = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    avg_precision_t = avg_precision * 100\n",
    "    avg_recall_t = avg_recall * 100\n",
    "    avg_f1_score_percentage_t = avg_f1_score_t * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Averagae accuracy:\", avg_accu, \"%\")\n",
    "print(\"Average Error:\", average_error_percentage_absolute_t, \"%\")\n",
    "print(\"Average F1 Score:\", avg_f1_score_percentage_t, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannyEdge_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac48c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error_percentage_absolute_c = 0\n",
    "t_accu_c = 0\n",
    "total_tp_c = 0\n",
    "total_fp_c = 0\n",
    "total_fn_c = 0\n",
    "num_images = len(image_paths)\n",
    "\n",
    "# Loop through each image and ground truth pair in the lists\n",
    "for image_path, ground_truth_image_path in zip(image_paths, ground_truth_paths):\n",
    "    # Load the image and ground truth\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply color thresholding\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply median filtering for image enhancement\n",
    "    median_filtered_image = cv2.medianBlur(binary_image, ksize=5)\n",
    "\n",
    "    # Perform morphological operations (closing and opening)\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    morph_img = cv2.morphologyEx(median_filtered_image, cv2.MORPH_CLOSE, kernel)\n",
    "    morph_img = cv2.morphologyEx(morph_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Contrast stretching for contrast enhancement\n",
    "    min_value = 40  # Define the lower bound of the intensity range\n",
    "    max_value = 100  # Define the upper bound of the intensity range\n",
    "    contrast_stretched_img = cv2.addWeighted(morph_img, 1.0, morph_img, 0.0, min_value)\n",
    "    contrast_stretched_img = cv2.addWeighted(contrast_stretched_img, 1.0, contrast_stretched_img, 0.0, -min_value + max_value)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(contrast_stretched_img, 30, 150)\n",
    "\n",
    "    # Display the results\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(edges, cmap='gray')\n",
    "    axs[1].set_title('Canny Edge Detected Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Find contours of the edges\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out smaller contours (noise) and detect only WBCs\n",
    "    wbc_contours = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 100:  # Adjust the threshold as needed\n",
    "            wbc_contours.append(contour)\n",
    "\n",
    "    # Create a blank image to draw the WBC contours\n",
    "    wbc_image = np.zeros_like(edges)\n",
    "\n",
    "    # Draw the WBC contours on the blank image\n",
    "    cv2.drawContours(wbc_image, wbc_contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Count the number of WBCs detected\n",
    "    num_wbcs_detected = len(wbc_contours)\n",
    "    num_cells = count_cells(ground_truth_image_path)\n",
    "    \n",
    "    if num_wbcs_detected > num_cells:\n",
    "        accuracy_c =  num_cells / num_wbcs_detected * 100\n",
    "    else:\n",
    "         accuracy_c =  num_wbcs_detected / num_cells * 100\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = min(num_wbcs_detected, num_cells)\n",
    "    fp = num_wbcs_detected - tp\n",
    "    fn = num_cells - tp\n",
    "\n",
    "    # Accumulate true positives, false positives, and false negatives for the average\n",
    "    total_tp_c += tp\n",
    "    total_fp_c += fp\n",
    "    total_fn_c += fn\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_score_percentage = f1_score * 100\n",
    "\n",
    "    print(\"Total number of cells (Ground Truth):\", num_cells)\n",
    "    print(\"Total number of cells (Detected):\", num_wbcs_detected)\n",
    "    \n",
    "    \n",
    "    #total accuracy\n",
    "    t_accu_c += accuracy_c\n",
    "    #average accuracy\n",
    "    avg_accu_c = t_accu_c/num_images\n",
    "    print(\"accuracy:\", accuracy_c,\"%\")\n",
    "    print(\"F1 Score:\", f1_score_percentage, \"%\")\n",
    "    \n",
    "    # Calculate the error percentage\n",
    "    error_percentage_c = 100 - accuracy_c\n",
    "\n",
    "    # Calculate the error percentage in absolute value\n",
    "    error_percentage_absolute_c = abs(error_percentage_c)\n",
    "    \n",
    "    # Print the error percentage for the current image\n",
    "    print(\"Error Percentage for current image:\", error_percentage_absolute_c, \"%\")\n",
    "    \n",
    "    # Accumulate the error percentage for the average\n",
    "    total_error_percentage_absolute_c += error_percentage_absolute_c\n",
    "    \n",
    "    # Calculate the average error percentage\n",
    "    average_error_percentage_absolute_c = total_error_percentage_absolute_c / num_images\n",
    "    \n",
    "    # Calculate the average precision, recall, and F1 score\n",
    "    avg_precision = total_tp_c / (total_tp_c + total_fp_c)\n",
    "    avg_recall = total_tp_c / (total_tp_c + total_fn_c)\n",
    "    avg_f1_score_c = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    avg_precision_c = avg_precision * 100\n",
    "    avg_recall_c = avg_recall * 100\n",
    "    avg_f1_score_percentage_c = avg_f1_score_c * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b64dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Averagae accuracy:\", avg_accu_c, \"%\")\n",
    "print(\"Average Error:\", average_error_percentage_absolute_c, \"%\")\n",
    "print(\"Average F1 Score:\", avg_f1_score_percentage_c, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd573a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall, Accuracy, and Error values for each model\n",
    "model_names = [\"Watershed Method\", \"Otsu's method\", \"Canny edge detector\"]\n",
    "precision_scores = [avg_precision_w, avg_precision_t, avg_precision_c]\n",
    "recall_scores = [avg_recall_w, avg_recall_t, avg_recall_c]\n",
    "accuracy_scores = [avg_accu_w, avg_accu, avg_accu_c]\n",
    "error_percentages = [average_error_percentage_absolute_w, average_error_percentage_absolute_t, average_error_percentage_absolute_c]\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 0.15\n",
    "gap_width = 0.05\n",
    "\n",
    "# Positions for the bars\n",
    "position = list(range(len(model_names)))\n",
    "\n",
    "# Create the grouped bar chart with gaps between bars\n",
    "plt.figure(figsize=(12, 10))\n",
    "bar1 = plt.bar(position, accuracy_scores, width=bar_width, label='Accuracy', color='skyblue')\n",
    "bar2 = plt.bar([p + bar_width + gap_width for p in position], error_percentages, width=bar_width, label='Error', color='salmon')\n",
    "bar3 = plt.bar([p + 2 * (bar_width + gap_width) for p in position], precision_scores, width=bar_width, label='Precision', color='lightgreen')\n",
    "bar4 = plt.bar([p + 3 * (bar_width + gap_width) for p in position], recall_scores, width=bar_width, label='Recall', color='orange')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Segmentation Methods', labelpad=20)\n",
    "plt.ylabel('Scores / Percentage')\n",
    "plt.title('Comparison of Segmentation Methods')\n",
    "plt.xticks([p + 1.5 * (bar_width + gap_width) for p in position], model_names)\n",
    "plt.legend()\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "def add_percentage_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "add_percentage_labels(bar1)\n",
    "add_percentage_labels(bar2)\n",
    "add_percentage_labels(bar3)\n",
    "add_percentage_labels(bar4)\n",
    "\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a2333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55405cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 scores for each model\n",
    "model_names = [\"Watershed Method\", \"Otsu's method\", \"Canny edge detector\"]\n",
    "f1_scores = [avg_f1_score_percentage_w, avg_f1_score_percentage_t, avg_f1_score_percentage_c]\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 0.5\n",
    "\n",
    "# Positions for the bars\n",
    "position = list(range(len(model_names)))\n",
    "\n",
    "# Create the bar chart for F1 scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(position, f1_scores, width=bar_width, color='skyblue')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Segmentation Methods',labelpad=20)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score for Segmentation Methods')\n",
    "plt.xticks([p for p in position], model_names)\n",
    "\n",
    "# Add F1 score values on top of each bar\n",
    "for i in range(len(model_names)):\n",
    "    plt.text(position[i], f1_scores[i] + 0.01, f'{f1_scores[i]:.2f}'+ '%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acb9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d01754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299965b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d995df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average precision, recall, F1 score, accuracy, and error for each method\n",
    "precision_values = [avg_precision_w, avg_precision_t, avg_precision_c]\n",
    "recall_values = [avg_recall_w, avg_recall_t, avg_recall_c]\n",
    "f1_score_values = [avg_f1_score_percentage_w, avg_f1_score_percentage_t, avg_f1_score_percentage_c]\n",
    "accuracy_values = [avg_accu_w, avg_accu, avg_accu_c]\n",
    "error_values = [average_error_percentage_absolute_w, average_error_percentage_absolute_t, average_error_percentage_absolute_c]\n",
    "\n",
    "\n",
    "\n",
    "# Method names for the x-axis\n",
    "methods = ['Watershed', \"Otsu's Method\", 'Canny Edge Detector']\n",
    "\n",
    "# Performance metrics in the desired order for the x-axis\n",
    "metrics = ['Accuracy', 'Error', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Plotting the performance comparison line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each method for each metric using a single line\n",
    "for i, method in enumerate(methods):\n",
    "    plt.plot(metrics, [accuracy_values[i], error_values[i], precision_values[i], recall_values[i], f1_score_values[i]],\n",
    "             marker='o', label=method)\n",
    "\n",
    "# Add legend, title, and labels\n",
    "plt.legend()\n",
    "plt.title('Performance Analysis of Segmentation Methods', fontsize=16)\n",
    "plt.xlabel('Metrics', fontsize=12, labelpad=20)\n",
    "plt.ylabel('Scores / Percentage', fontsize=12)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks()\n",
    "\n",
    "# Set y-axis ticks with an increment of 5\n",
    "plt.yticks(range(0, 111, 10))\n",
    "\n",
    "# Customize grid style\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Set background color\n",
    "plt.gca().set_facecolor('whitesmoke')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae031c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c21029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average precision, recall, F1 score, accuracy, and error for each method\n",
    "precision_values = [avg_precision_w, avg_precision_t, avg_precision_c]\n",
    "recall_values = [avg_recall_w, avg_recall_t, avg_recall_c]\n",
    "f1_score_values = [avg_f1_score_percentage_w, avg_f1_score_percentage_t, avg_f1_score_percentage_c]\n",
    "accuracy_values = [avg_accu_w, avg_accu, avg_accu_c]\n",
    "error_values = [average_error_percentage_absolute_w, average_error_percentage_absolute_t, average_error_percentage_absolute_c]\n",
    "\n",
    "# Method names for the x-axis\n",
    "methods = ['Watershed', \"Otsu's Method\", 'Canny Edge Detector']\n",
    "\n",
    "# Performance metrics in the desired order\n",
    "metrics = ['Accuracy', 'Error', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Colorful lines for each graph\n",
    "line_colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Plotting the performance line graphs for each method\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a subplot for each method\n",
    "for i, method in enumerate(methods):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    plt.plot(metrics, [accuracy_values[i], error_values[i], precision_values[i], recall_values[i], f1_score_values[i]],\n",
    "             marker='o', color=line_colors[i])\n",
    "    plt.title(f'{method} Performance Metrics')\n",
    "    plt.xlabel('Metrics',fontsize=12, labelpad=20)\n",
    "    plt.ylabel('Scores / Percentage')\n",
    "    plt.ylim(0, 110)\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a5990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11bc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
